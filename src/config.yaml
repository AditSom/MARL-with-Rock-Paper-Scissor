# Configuration file for MARL with Rock-Paper-Scissor

# Grid settings
grid_size: 5  # Overriding the default grid size to 5x5

# Agent settings
agents: [1,1]  # 2 agents of type 0 and 2 agents of type 1

# Prey-predator relationship
prey_predator_combo:
  0: 1  # Type 1 can capture Type 0
  1: None  # Type 0 cannot capture Type 1

# Reward settings
reward:
  win: 1          # Reward for winning
  lose: -1        # Penalty for losing
  captured: 1     # Reward for capturing
  eliminated: -1  # Penalty for being eliminated
  step: -0.1      # Penalty for each step taken
  prey_step: 0.1  # Penalty for each step taken by the prey
  distance: -1  # Penalty for each unit distance
  boundary: -0.1  # Penalty for hitting the boundary

# Animation settings
animation: True  # Enable animation
fps: 3  # Frame rate for animation

# Position settings
position_random: True  # Enable random positions

# Capture settings
capture: False  # Prey is eliminated, not captured

# Training Hyperparameters
n_actions: 5  # Number of possible actions
num_episodes: 10000  # Number of training episodes
max_steps: 15  # Maximum steps per episode
model: "dqn"  # Model type
hidden_dim: [64, 128, 256, 128, 64]  # Hidden layer dimensions

# Save path for results
save_path: "results/"  # Absolute path to the experiments folder

# Tag for the experiment
tag: "trial_57"

# Path to the custom config file
config_file: "src/config.yaml"

# Plot settings
smooth_plot: True  # Smooth the training plot

# Animation batch size
ani_batch_size: 50  # Batch size for animation

# Distance settings
distance: True
distance_type: "average"  # Type of distance calculation: "average" or "last"

# Animation settings for max step
max_step_ani: True  # Animate the max step

# Boundary settings
boundary: True

# Distance input settings
distance_input: True

# Experience replay settings
experience_replay: True

# Batch size for training
batch_size: 32